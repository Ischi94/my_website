---
title: "One sample t-test"
author: "Gregor Mathes"
date: "2021-03-27"
slug: Regression tests
categories: []
tags: [Regression, t-test, Bayes, Statistics]
subtitle: ''
summary: 'Modeling the central tendency within one sample'
authors: [Gregor Mathes]
lastmod: "27 März, 2021"
featured: no
projects: [Regression tests]
output:
  blogdown::html_page:
    toc: true
    toc_depth: 1
    number_sections: false
    fig_width: 6
---

<script src="/rmarkdown-libs/header-attrs/header-attrs.js"></script>

<div id="TOC">
<ul>
<li><a href="#introduction">Introduction</a></li>
<li><a href="#one-sample-t-test">One sample t-test</a></li>
<li><a href="#comparing-the-test-to-the-regression">Comparing the test to the regression</a></li>
<li><a href="#comparison">Comparison</a></li>
</ul>
</div>

<div id="introduction" class="section level1">
<h1>Introduction</h1>
<p>I have a very weird relationship to statistics. Even though I was very bad at maths, I decided to study geosciences. I somehow managed to get through the Bachelor maths exams. For some reason, I then proceeded with a shiny new Master program called <a href="http://www.palaeobiology.de/">Analytical Paleobiology</a> that was build around the R programming software and a lot of statistics (it’s an amazing research-oriented programm with lots of fossils, stats and outreach courses). During the first lectures, we learned about frequentist null hypothesis testing and p-values. It was very confusing, and it is still today. We also learned how to use statistical tests such as a <em>t-test</em> or an <em>ANOVA</em>. It was even more confusing. We’ve got told that these tests are small little black-boxes and that we should not trust them. Then every one just proceeded to work with those black boxes, completely trusting them.<br />
During that Master program I found my passion for stats and programming. Since then, I have read a lot of statistic textbooks and blogs, something that I could never explain my former self that disliked maths. With all this amazing new knowledge, a few things cleared up for me:</p>
<ol style="list-style-type: decimal">
<li>frequentist null hypothesis testing makes no sense<br />
</li>
<li>p-values make no sense<br />
</li>
<li>statistical tests are just regression in disguise</li>
</ol>
<p>I somehow managed to avoid (1) and (2) by using resampling and permutation methods, and by sticking to effect sizes instead of p-values. Lately, I started to work with Bayesian estimates, completely ditching the frequentist approach (and I will never look back). But statistical tests are still important in my daily work-flow and I simply don’t want to use black boxes anymore. So, basically as a resource to future me, I decided to start a series of blog posts on statistical tests. In each blog post, I will cover one commonly used statistical test and show that it’s just a regression (and that you get much more power if you express the test as a regression model). I will then proceed to fit a Bayesian regression model for each test, because as John Kruschke states it in the amazing paper <em>Bayesian Estimation Supersedes the t Test</em>:</p>
<blockquote>
<p>Some people may wonder which approach, Bayesian or NHST, is more often correct. This question has limited applicability because in real research we never know the ground truth; all we have is a sample of data. If we knew the ground truth, against which to compare the conclusion from the statistical analysis, we would not
bother to collect the data. If the question of correctness is instead asked of some hypothetical data generator, the assessment is confined to that particular distribution of simulated data, which likely has only limited resemblance to real-world data encountered across research paradigms. Therefore, instead of asking which
method is more often correct in some hypothetical world of simulated data, the relevant question is asking which method provides the richest, most informative, and meaningful results for any set of data. The answer is always Bayesian estimation.</p>
</blockquote>
<p>Additionally, using Bayesian estimation, we can quickly escape the omnipresent assumption of normality of many statistical tests. I will start in this blog post with the one sample t-test.</p>
</div>
<div id="one-sample-t-test" class="section level1">
<h1>One sample t-test</h1>
<div id="when-to-use" class="section level2">
<h2>When to use</h2>
<p>If you have one sample of measurements and you want to estimate the central tendency of this sample (e.g. the mean) compared to a specific value. For example, assume I want to test whether my males from my family tends to be smaller than the average male human height. If heights across my male family members are normally distributed, I can use the one sample t-test.</p>
</div>
<div id="assumptions" class="section level2">
<h2>Assumptions</h2>
<p>Your sample should have the following characteristics:</p>
<ol style="list-style-type: decimal">
<li>continuous (not discrete).<br />
</li>
<li>normally distributed<br />
</li>
<li>a random sample from its population with each individual in the population having an equal
probability of being selected in the sample</li>
</ol>
</div>
<div id="as-a-regression" class="section level2">
<h2>As a regression</h2>
<p>All we need is a regression that approximates the mean of the sample. Back in high-school, we learned that the intercept of a regression line goes through the mean of the data. So all we need is a regression with an intercept and nothing less. We can state this as <span class="math display">\[\mu = \alpha\]</span> where <span class="math inline">\(\alpha\)</span> is the intercept and <span class="math inline">\(\mu\)</span> the height of each individual. Note that the t-test assumes that height is normally distributed, which we can express as <span class="math display">\[height \sim Normal(\mu, \sigma)\]</span></p>
</div>
</div>
<div id="comparing-the-test-to-the-regression" class="section level1">
<h1>Comparing the test to the regression</h1>
<div id="the-data" class="section level2">
<h2>The data</h2>
<p>First, we will simulate some data for my male family members height. By simulating the data, we know the true values and can therefore see how each method performs.</p>
<pre class="r"><code>set.seed(1708)
dat_height &lt;- rnorm(100, 160, 2)

head(dat_height)</code></pre>
<pre><code>## [1] 162.0337 159.4832 157.5617 158.4347 159.5004 161.0900</code></pre>
<p>So we just generated 100 height values from a normal distribution with mean 160 cm and a standard deviation of 2. Now we just need a value for the average height of all males. Google says that <em>The global mean height of adult men born in 1996 is 171 centimetres (cm)</em>.</p>
</div>
<div id="the-black-box" class="section level2">
<h2>The black box</h2>
<p>Here’s how you fit the one sample t-test in R:</p>
<pre class="r"><code>result_ttest &lt;- t.test(dat_height, mu = 171)</code></pre>
<p>We just feed in our data and define the value to which the sample mean should be compared to using <code>mu = 171</code>. The output of this function is very verbose and it’s really painful to extract any values from it.</p>
<pre class="r"><code>result_ttest</code></pre>
<pre><code>## 
##  One Sample t-test
## 
## data:  dat_height
## t = -54.239, df = 99, p-value &lt; 2.2e-16
## alternative hypothesis: true mean is not equal to 171
## 95 percent confidence interval:
##  159.4753 160.2887
## sample estimates:
## mean of x 
##   159.882</code></pre>
<p>We get a p-value as output that states the probability to get a value of 159.882 cm (the mean from my male family members) if the true mean would be 171 cm (average male). The p-value is very low, certainly below many commonly used thresholds, so we could reject the null hypothesis. Are you already confused? Let’s focus on the effect size instead. The mean of my male family members is 159.882, and those members are therefore 11.118 cm (171 - 159.882 cm) smaller as the average male. As we get a confidence interval for the mean as well, we can transform it as well:</p>
<pre class="r"><code>ci_ttest &lt;- result_ttest$conf.int %&gt;% 
  as.vector()
171 - ci_ttest</code></pre>
<pre><code>## [1] 11.52475 10.71130</code></pre>
<p>So male members from my family are 11.12 cm smaller than the average human male, with a 95% CI of [11.52, 10.71].</p>
</div>
<div id="the-regression" class="section level2">
<h2>The regression</h2>
<p>To fit a linear regression in R with just an intercept, we can use the formula <code>sample ~ 1</code>. But with this formula, any output that we get compares the mean to a threshold of 0. But we want it to be compared to a threshold of 171, the average human males height. So we need to subtract 170 from each sample first.</p>
<pre class="r"><code>result_lm &lt;- lm(dat_height - 171 ~ 1) </code></pre>
<p>A real cool thing with this regression approach is that we get the direct difference in means. Let’s take a look:</p>
<pre class="r"><code>summary(result_lm)</code></pre>
<pre><code>## 
## Call:
## lm(formula = dat_height - 171 ~ 1)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -4.694 -1.292  0.074  1.094  6.198 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  -11.118      0.205  -54.24   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 2.05 on 99 degrees of freedom</code></pre>
<p>The p-value is similarly small and the difference is equal to the one sample t-test approach: My male family members are on average 11.12 cm smaller. We can get the confidence intervals with <code>confint()</code>.</p>
<pre class="r"><code>confint(result_lm)</code></pre>
<pre><code>##                 2.5 %   97.5 %
## (Intercept) -11.52475 -10.7113</code></pre>
<p>Coolio, we obviously get the same results. It seems like the one sample t-test is just a regression in disguise.<br />
# Bayesian regression</p>
<p>Now we get to the gold standard, the Bayesian estimation. I will use the <code>brms</code> package for that, which is R’s interface to the Stan language, using a Hamiltonian Markov Chain Monte Carlo and the Nuts sampler. Or as Andrew Heiss stated it in one of his blog posts:<br />
&gt; … all the cool kids are using Stan.</p>
<pre class="r"><code>library(brms)
options(mc.cores = parallel::detectCores())  # Use all cores</code></pre>
<p>For Bayesian analysis, we can additionally set a prior on the intercept. I will not go into detail, but notice that we can help the model to run by using our knowledge. We do this by setting a weakly informative prior on the intercept with a normal distribution with a mean of 170 and a standard deviation of 3. Why these specific values? Because most males I have seen in my life fall within this range, and it is just reasonable to assume that our sample has similar values. Either way, the prior is so broad that it is easily overwhelmed by the data (it <em>listens</em> to the data), but the model does not assume some very irrealistic values like a height of thousand meters for a human male, or even negative values. We can even visualise the prior:</p>
<pre class="r"><code>tibble(height = rnorm(1e5, 170, 10)) %&gt;% 
  ggplot(aes(height)) +
  geom_density() +
  theme_minimal()</code></pre>
<p><img src="/post/one_sample_t_test_files/figure-html/prior-1.png" width="576" /></p>
<p>And as we don’t need to fiddle with the meaning of a p-value anymore, I will directly model the mean for our samples using the formule <code>dat_height ~ 1</code> and then compare these values to the average human male height using posterior samples.</p>
<pre class="r"><code>result_brms &lt;- brm(
  bf(dat_height ~ 1), 
  prior = c(set_prior(&quot;normal(170, 10)&quot;, class = &quot;Intercept&quot;)),
  chains = 3, iter = 2000, warmup = 1000, data = tibble(dat_height = dat_height))</code></pre>
<p>That’s it. We can get a summary of this model as well:</p>
<pre class="r"><code>summary(result_brms)</code></pre>
<pre><code>##  Family: gaussian 
##   Links: mu = identity; sigma = identity 
## Formula: dat_height ~ 1 
##    Data: tibble(dat_height = dat_height) (Number of observations: 100) 
## Samples: 3 chains, each with iter = 2000; warmup = 1000; thin = 1;
##          total post-warmup samples = 3000
## 
## Population-Level Effects: 
##           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## Intercept   159.89      0.21   159.48   160.29 1.00     2584     1983
## 
## Family Specific Parameters: 
##       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sigma     2.07      0.15     1.80     2.38 1.00     2337     1767
## 
## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS
## and Tail_ESS are effective sample size measures, and Rhat is the potential
## scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
<p>The Rhat values are equal 1 and the effective sample sizes are large, indicating low autocorrelation. So our model fitted just fine. One great advantage of Bayesian estimation (and Hamiltonian MCMC in particular) is that the model would tell us if something is wrong.The estimate shows the mean for my family members as well as 95% credible intervals. But stop, with frequentist approaches we get only point estimates like these, but with Bayesian estimation we get the whole distribution from the MCMC. Let’s take a look:</p>
<pre class="r"><code>result_posterior &lt;- posterior_samples(result_brms)

result_posterior %&gt;% 
  ggplot(aes(b_Intercept)) +
  geom_density(colour = &quot;grey20&quot;, fill = &quot;firebrick&quot;, alpha = 0.8) +
  labs(x = &quot;Mean height&quot;, y = NULL) + 
  theme_minimal() </code></pre>
<p><img src="/post/one_sample_t_test_files/figure-html/posterior-1.png" width="576" /></p>
<p>You see that we get aaaall the information we need. What do I mean with that? We get a whole distribution instead of a point estimate (the best guess of ordinary least squares or maximum likelihood) or a range (the confidence interval). So we can take all samples into account and summarize them as we please, using the mean, median, mode and percentile intervals, highest posterior density intervals or credible intervals. We have the power. This is another great advantage of Bayesian estimation. Note also that the model assumes that the response variable (height) comes from a normal distribution. But we are not limited to that (as we are with the t-test and a basic ordinary least squares regression). We can simply change the link function for the response distribution with <code>family = ...</code>.<br />
Now to the interpretation: The whole distribution does not include the average human male height of 171 cm, so we can conclude that my male family members are credibly smaller than the average human male. We could even do some Bayesian hypothesis testing to prove this:</p>
<pre class="r"><code>hypothesis(result_brms, &quot;Intercept &lt; 171&quot;)</code></pre>
<pre><code>## Hypothesis Tests for class b:
##              Hypothesis Estimate Est.Error CI.Lower CI.Upper Evid.Ratio
## 1 (Intercept)-(171) &lt; 0   -11.11      0.21   -11.46   -10.78        Inf
##   Post.Prob Star
## 1         1    *
## ---
## &#39;CI&#39;: 90%-CI for one-sided and 95%-CI for two-sided hypotheses.
## &#39;*&#39;: For one-sided hypotheses, the posterior probability exceeds 95%;
## for two-sided hypotheses, the value tested against lies outside the 95%-CI.
## Posterior probabilities of point hypotheses assume equal prior probabilities.</code></pre>
<p>As the credible interval does not include zero and the evidence ratio is really high, we can accept the hypothesis that my family male members have a mean height smaller than 171 cm. What did I just say? Accepting a hypothesis is not possible, right? But this is only true for frequentist approeaches and not for Bayesian one. The p-value of a frequentist approach gives us the probability for the data given a null hypothesis <span class="math display">\[p(data | N_0)\]</span> Bayesian estimation instead gives us the probability of a hypothesis given the data <span class="math display">\[p(N_0 | data)\]</span> This is basically what we wanted from the beginning.</p>
</div>
</div>
<div id="comparison" class="section level1">
<h1>Comparison</h1>
<p>Let’s compare the estimates of all approaches.</p>
<pre class="r"><code>tibble(Model = c(&quot;T-Test&quot;, 
                 &quot;OLS Regression&quot;, 
                 &quot;Bayesian Regression&quot;),
       Estimate = c(result_ttest$estimate - 171, 
                    result_lm$coefficients, 
                    fixef(result_brms)[1] - 171), 
       Est_Error = c(result_ttest$stderr,
                     summary(result_lm)$coefficients[2], 
                     fixef(result_brms)[2]),
       Lower_CI = c(result_ttest$conf.int[1] -171, 
                    confint(result_lm)[1], 
                    fixef(result_brms)[3] - 171), 
       Upper_CI = c(result_ttest$conf.int[2] -171, 
                    confint(result_lm)[2], 
                    fixef(result_brms)[4] - 171),
       p_Value = c(result_ttest$p.value, 
                   summary(result_lm)$coefficients[4], 
                   NA)) %&gt;% 
  mutate(across(Estimate:Upper_CI, round, 2)) %&gt;% 
  knitr::kable(digits = 100)</code></pre>
<table>
<thead>
<tr class="header">
<th align="left">Model</th>
<th align="right">Estimate</th>
<th align="right">Est_Error</th>
<th align="right">Lower_CI</th>
<th align="right">Upper_CI</th>
<th align="right">p_Value</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">T-Test</td>
<td align="right">-11.12</td>
<td align="right">0.20</td>
<td align="right">-11.52</td>
<td align="right">-10.71</td>
<td align="right">1.928903e-75</td>
</tr>
<tr class="even">
<td align="left">OLS Regression</td>
<td align="right">-11.12</td>
<td align="right">0.20</td>
<td align="right">-11.52</td>
<td align="right">-10.71</td>
<td align="right">1.928903e-75</td>
</tr>
<tr class="odd">
<td align="left">Bayesian Regression</td>
<td align="right">-11.11</td>
<td align="right">0.21</td>
<td align="right">-11.52</td>
<td align="right">-10.71</td>
<td align="right">NA</td>
</tr>
</tbody>
</table>
<p>That looks very good. Note that the CI is a 95% confidence interval for the frequentist approaches, and a 95% credible interval for the Bayesian estimation. To sum this up: The t-test is nothing but a regression, and we can always do better than a OLS regression by using a Bayesian regression. Why? Because in stark contrast to all frequentist approaches, it gives us the answers we want.</p>
<hr />
<pre class="r"><code>sessionInfo()</code></pre>
<pre><code>## R version 4.0.4 (2021-02-15)
## Platform: x86_64-pc-linux-gnu (64-bit)
## Running under: Linux Mint 20.1
## 
## Matrix products: default
## BLAS:   /usr/lib/x86_64-linux-gnu/blas/libblas.so.3.9.0
## LAPACK: /usr/lib/x86_64-linux-gnu/lapack/liblapack.so.3.9.0
## 
## locale:
##  [1] LC_CTYPE=de_DE.UTF-8       LC_NUMERIC=C              
##  [3] LC_TIME=de_DE.UTF-8        LC_COLLATE=de_DE.UTF-8    
##  [5] LC_MONETARY=de_DE.UTF-8    LC_MESSAGES=de_DE.UTF-8   
##  [7] LC_PAPER=de_DE.UTF-8       LC_NAME=C                 
##  [9] LC_ADDRESS=C               LC_TELEPHONE=C            
## [11] LC_MEASUREMENT=de_DE.UTF-8 LC_IDENTIFICATION=C       
## 
## attached base packages:
## [1] stats     graphics  grDevices utils     datasets  methods   base     
## 
## other attached packages:
##  [1] brms_2.15.0     Rcpp_1.0.6      forcats_0.5.0   stringr_1.4.0  
##  [5] dplyr_1.0.3     purrr_0.3.4     readr_1.4.0     tidyr_1.1.2    
##  [9] tibble_3.0.5    ggplot2_3.3.3   tidyverse_1.3.0
## 
## loaded via a namespace (and not attached):
##   [1] minqa_1.2.4          colorspace_2.0-0     ellipsis_0.3.1      
##   [4] ggridges_0.5.3       rsconnect_0.8.16     markdown_1.1        
##   [7] base64enc_0.1-3      fs_1.5.0             rstudioapi_0.13     
##  [10] farver_2.0.3         rstan_2.21.2         DT_0.17             
##  [13] fansi_0.4.2          mvtnorm_1.1-1        lubridate_1.7.9.2   
##  [16] xml2_1.3.2           codetools_0.2-18     bridgesampling_1.0-0
##  [19] splines_4.0.4        knitr_1.30           shinythemes_1.2.0   
##  [22] bayesplot_1.8.0      projpred_2.0.2       jsonlite_1.7.2      
##  [25] nloptr_1.2.2.2       broom_0.7.3          dbplyr_2.0.0        
##  [28] shiny_1.6.0          compiler_4.0.4       httr_1.4.2          
##  [31] backports_1.2.1      assertthat_0.2.1     Matrix_1.3-2        
##  [34] fastmap_1.1.0        cli_2.2.0            later_1.1.0.1       
##  [37] prettyunits_1.1.1    htmltools_0.5.1.1    tools_4.0.4         
##  [40] igraph_1.2.6         coda_0.19-4          gtable_0.3.0        
##  [43] glue_1.4.2           reshape2_1.4.4       V8_3.4.0            
##  [46] cellranger_1.1.0     vctrs_0.3.6          nlme_3.1-152        
##  [49] blogdown_1.1         crosstalk_1.1.1      xfun_0.20           
##  [52] ps_1.5.0             lme4_1.1-26          rvest_0.3.6         
##  [55] mime_0.9             miniUI_0.1.1.1       lifecycle_0.2.0     
##  [58] gtools_3.8.2         statmod_1.4.35       MASS_7.3-53.1       
##  [61] zoo_1.8-8            scales_1.1.1         colourpicker_1.1.0  
##  [64] hms_1.0.0            promises_1.1.1       Brobdingnag_1.2-6   
##  [67] parallel_4.0.4       inline_0.3.17        shinystan_2.5.0     
##  [70] curl_4.3             gamm4_0.2-6          yaml_2.2.1          
##  [73] gridExtra_2.3        StanHeaders_2.21.0-7 loo_2.4.1           
##  [76] stringi_1.5.3        highr_0.8            dygraphs_1.1.1.6    
##  [79] pkgbuild_1.2.0       boot_1.3-27          rlang_0.4.10        
##  [82] pkgconfig_2.0.3      matrixStats_0.57.0   evaluate_0.14       
##  [85] lattice_0.20-41      labeling_0.4.2       rstantools_2.1.1    
##  [88] htmlwidgets_1.5.3    processx_3.4.5       tidyselect_1.1.0    
##  [91] plyr_1.8.6           magrittr_2.0.1       bookdown_0.21       
##  [94] R6_2.5.0             generics_0.1.0       DBI_1.1.1           
##  [97] pillar_1.4.7         haven_2.3.1          withr_2.4.1         
## [100] mgcv_1.8-33          xts_0.12.1           abind_1.4-5         
## [103] modelr_0.1.8         crayon_1.3.4         rmarkdown_2.6       
## [106] grid_4.0.4           readxl_1.3.1         callr_3.5.1         
## [109] threejs_0.3.3        reprex_1.0.0         digest_0.6.27       
## [112] xtable_1.8-4         httpuv_1.5.5         RcppParallel_5.0.2  
## [115] stats4_4.0.4         munsell_0.5.0        shinyjs_2.0.0</code></pre>
</div>
